# Документация
### ideas/
Неудавшиеся идеи лежат в папке ideas/ Там лежит код для различных аугментаций, также лежит код Unet с temporal attention, который по итогу показал плохие результаты. Лежат аугментация с изменениям цвета воды для улучшения стабильности модели и triplet.ipynb в котором тестировался так называемый triplet rule, который по трем значения threshold(гиперпараметры) определяет по скору пикселя, выданному нашей моделью,  что это пиксель воды или нет. 

### dataset.py
Модуль для предобработки и работы с набором данных спутниковых изображений и масок

Этот модуль содержит функции и классы, предназначенные для предобработки изображений, загрузки и подготовки данных для дальнейшей работы с моделями глубокого обучения. Он включает функции для нормализации, обрезки, дополнения (padding), а также класс WaterDataset, который предоставляет интерфейс для работы с набором данных.
Содержание

    Функции предобработки и вспомогательные функции:
        natural_sort_key(s): Генерирует ключ для естественной сортировки строк, содержащих числа.
        process_and_save_image(image_path, output_folder): Загружает TIFF-изображение, нормализует его RGB-каналы и сохраняет обработанное изображение в формате PNG.
        image_padding(image, target_size=256): Дополняет изображение до заданного размера (по умолчанию 256x256) с помощью отражающего дополнения.
        mask_padding(mask, target_size=256): Дополняет маску до заданного размера с использованием отражающего дополнения.
        get_data_list(img_path): Извлекает список имен файлов из указанного каталога и возвращает их в виде массива.

    Класс WaterDataset:
        Класс для создания настраиваемого датасета на основе библиотеки PyTorch для работы с наборами данных изображений и масок.

Функции
natural_sort_key(s)

Генерирует ключ для сортировки строк, содержащих числа, в естественном порядке. Это полезно для сортировки имен файлов, в которых встречаются цифры, чтобы файлы сортировались в интуитивно понятном порядке (например, "image1", "image2", "image10" и т.д.).
process_and_save_image(image_path, output_folder)

Загружает TIFF-изображение с указанным путем image_path, нормализует его RGB-каналы, изменяет размер до 256x256 и сохраняет в формате PNG в указанный каталог output_folder. Создает каталог, если он не существует.

Параметры:

    image_path (str): Путь к исходному TIFF-изображению.
    output_folder (str): Путь для сохранения нормализованного изображения.

image_padding(image, target_size=256)

Дополняет изображение до заданного размера target_size с использованием отражающего дополнения. Используется для приведения изображений к одинаковому размеру, что необходимо для пакетной обработки.
mask_padding(mask, target_size=256)

Аналогично image_padding, дополняет маску до нужного размера с помощью отражающего дополнения.
get_data_list(img_path)

Извлекает имена всех файлов в указанном каталоге и возвращает их в виде массива, отсортированного в естественном порядке. Пропускает первый файл (по всей видимости, предназначено для пропуска метаданных или другой вспомогательной информации).

Параметры:

    img_path (str): Путь к каталогу изображений.

Класс WaterDataset

Класс WaterDataset наследуется от torch.utils.data.Dataset и предназначен для загрузки изображений и их масок с возможностью предварительной обработки. Предназначен для использования в задачах сегментации и классификации.
Параметры:

    img_path (str): Путь к каталогу изображений.
    file_names (list[str]): Список имен файлов изображений, которые будут использованы в датасете.
    mask_path (str, optional): Путь к каталогу масок.
    original_image_path (str, optional): Путь к каталогу оригинальных изображений, которые будут использоваться для извлечения дополнительных каналов.

Методы:

    __len__(): Возвращает количество изображений в наборе данных.
    __getitem__(idx): Загружает изображение и его маску (если указано) по индексу idx, выполняет дополнение для приведения к требуемому размеру и возвращает данные в виде массива NumPy.

Логика:

    Обработка оригинальных изображений: При инициализации, если каталог original_resized_images пуст, изображения из original_image_path обрабатываются функцией process_and_save_image и сохраняются в уменьшенном формате.
    Добавление дополнительных каналов: При загрузке каждого изображения к ним добавляется дополнительный канал NDWI (Normalized Difference Water Index), который рассчитывается как разница нормализованных значений в каналах, связанных с водой.
    Работа с масками: Если передан параметр mask_path, соответствующая маска также дополняется и возвращается вместе с изображением.


### fit.py
Этот скрипт предназначен для обучения модели сегментации (например, UNet++) на наборе данных изображений и их масок, включая различные функции предобработки и методику логирования метрик. Он реализует процесс обучения и валидации для задачи сегментации водоемов с использованием библиотеки PyTorch и библиотеки segmentation_models_pytorch.
Основные компоненты и функции скрипта

    Импорт библиотек и компонентов:
        Импортируются необходимые библиотеки для работы с PyTorch, DataLoader, обработкой данных и разделением датасета на тренировочный и тестовый наборы.

    Функция train_test_split_files:
        Разделяет файлы изображений и масок на тренировочный и тестовый наборы.
        Выполняет проверку на наличие изображений и масок с одинаковыми именами и корректно создает соответствующие списки файлов.
        На данный момент настроена для использования файлов с именем, содержащим "5.tif", в качестве тестовых, а остальные – для тренировочного набора.

    Функция train_model:
        Выполняет обучение модели на основе заданных критериев потерь, оптимизатора и планировщика обучения.
        Поддерживает накопление градиентов через параметр accumulation_steps и включает процедуру логирования метрик.
        Каждую эпоху выполняется валидация модели с помощью функции validate, и в случае достижения лучшего значения потерь на валидации, сохраняет текущие веса модели.

    Функция main:
        Основная функция, выполняющая следующие задачи:
            Инициализирует гиперпараметры обучения, устройство (GPU или CPU) и пути к данным.
            Загружает файлы изображений и масок, разделяет их на тренировочную и тестовую выборки.
            Создает объекты классов WaterDataset для тренировочного и тестового наборов данных.
            Инициализирует модель UnetPlusPlus с энкодером resnet50, критерий потерь и оптимизатор, а также планировщик обучения.
            Вызывает функцию train_model для обучения модели.

    Запуск скрипта:
        Запускает основную функцию main при выполнении скрипта напрямую.

Особенности настройки и дальнейших шагов

    В зависимости от структуры имен файлов и требований, настройте фильтрацию и разбиение в train_test_split_files.
    Настройте пути для сохранения весов модели и логов в train_model.
    Оцените необходимость дополнительных обработок данных для улучшения результатов и гибкости.


### inference.py
Этот скрипт выполняет предсказание масок для крупных спутниковых снимков с использованием обученной модели UNet++ и PyTorch. Вот краткий обзор ключевых функций и компонентов:
Основные функции скрипта:

    Разбиение изображения на тайлы с перекрытием:
        Функция get_tiles_with_overlap создает список окон (тайлов) для разбиения исходного изображения с учетом заданного размера тайла и количества перекрытий.
        split_image использует этот список окон для разбиения исходного изображения (и его маски, если она предоставлена) на тайлы, которые затем сохраняются.

    Сохранение тайла:
        Функция save_tile сохраняет каждое окно изображения или маски как отдельный .tif файл в нужной папке.
        Она обновляет профиль для каждого тайла, чтобы обеспечить правильные размеры и трансформацию.

    Получение предсказаний модели:
        Функция get_model_outputs выполняет предсказание на каждом батче данных из dataloader, используя модель сегментации.
        Предсказанные значения для каждого пикселя сохраняются в тензоре, который затем используется для восстановления исходного изображения.

    Воссоздание изображения из предсказанных тайлов:
        make_tif_from_outputs собирает итоговое изображение из предсказанных тайлов, применяя среднее в местах перекрытий, и сохраняет итоговую маску в формате .tif.
        Также устанавливается корректное геопространственное преобразование (при наличии).

    Функция inference:
        Основная функция, которая вызывает остальные для выполнения инференса. Она:
            Разбивает исходное изображение на тайлы.
            Выполняет предсказание маски для каждого тайла.
            Сохраняет результат как единое изображение в формате .tif.

    Главная функция main:
        Инициализирует модель и загружает предобученные веса.
        Выполняет инференс для каждого .tif файла в папке с изображениями и сохраняет предсказанную маску в заданной папке.

Основные моменты, на которые стоит обратить внимание:

    Параметры разбиения: Параметры tile_size и overlap важно настроить в зависимости от задачи и разрешения изображений.
    Загрузка весов модели: Убедитесь, что model_weights_path указывает на корректный файл весов.
    Корректное геопространственное преобразование: Функция get_transform_from_image извлекает и передает параметр transform, чтобы сохранить геопространственные координаты результирующего файла.

Этот скрипт является комплексным решением для генерации предсказаний по маскам из крупных изображений. Если требуется, можно добавить дополнительные этапы для оценки качества предсказаний и постобработки результатов.

### validate.py
Функция validate предназначена для оценки сегментационной модели на валидационном наборе данных. Она вычисляет средние значения функции потерь, а также основные метрики: точность (Precision), полноту (Recall) и F1-меру.
Параметры:

    model (torch.nn.Module):
        Сегментационная модель, которую необходимо оценить.
    dataloader (torch.utils.data.DataLoader):
        Даталоадер для валидационного набора данных. Содержит изображения и метки истинных классов.
    criterion (torch.nn.Module):
        Основная функция потерь, которая используется для вычисления ошибки модели на каждом батче.
    criterion2 (torch.nn.Module, по умолчанию None):
        Дополнительная функция потерь, которая используется для комбинированной оценки. Если указана, комбинированный показатель потерь рассчитывается как среднее значение criterion и criterion2.
    device (str, по умолчанию cuda):
        Устройство, на котором выполняется оценка (cuda для GPU или cpu).

Возвращаемые значения:

    tuple: (avg_loss, avg_precision, avg_recall, avg_f1), где:
        avg_loss (float): Средняя потеря на валидационном наборе.
        avg_precision (float): Средняя точность модели на валидационном наборе данных.
        avg_recall (float): Средний отзыв модели на валидационном наборе данных.
        avg_f1 (float): Средняя F1-мера модели на валидационном наборе данных.

Описание работы:

Функция переводит модель в режим оценки и отключает вычисление градиентов, что повышает скорость работы и уменьшает использование памяти. Она выполняет проход по валидационному набору данных и вычисляет среднее значение функции потерь. Также для каждого батча подсчитываются метрики точности, полноты и F1-меры. Финальные метрики усредняются для всей валидационной выборки, что позволяет объективно оценить модель на данном наборе данных.
